# (ur "reality") - Core UX Vision & Organization

## Overview
This document captures the fundamental UX philosophy and organizational structure of **(ur "reality")**. This vision emerged from Story 2.10 (Physical/Mental realm connection) which revealed the need for cohesive organization across the entire web app.

**Note on Branding**: The name is intentionally styled as **(ur "reality")** with quotes and parentheses to maintain a playful, sarcastic tone - preventing people from taking it too seriously.

## Development Approach

**Core Philosophy**:
- To figure out how to store somethings correctly, we must first understand what we're going to DO with somethings
- Building step-by-step, epic-by-epic as we go (no massive upfront architecture)
- Easy to change direction without losing anything (ideas exist, but not as rigid specs)
- Must incorporate existing information - no rederiving from scratch

**Status**:
- ‚úì Captures table renamed to `somethings` (good foundational decision)
- Planning: Phased approach, likely new epic
- Next: Define the vision past capture pages (what happens with somethings)

---

## 1. Core Philosophy & Vision

### The Dual Structure: Reality vs. My Reality

**Two Fundamental Aspects**:

1. **REALITY** - The playfield that matters
   - Where we are human
   - Where it starts, where you live
   - Where others are, where you connect with people
   - The inarguable part you have to live in and start from

2. **MY REALITY** - What I know
   - Your realm of thought
   - Built off of reality
   - A chamber of reflection

**The Relationship**:
- **Reality IS being human** - experienced through the 6 realms of human senses:
  - Touch
  - Smell
  - Taste
  - Sound
  - Sight
  - Feeling (heart)
- **My Reality** is a tool to enhance your experience of reality
- All this computer stuff is just to **figure out your intention**, but the point is to **return to reality, being human**

**Truth vs. Experience**:
- Our reality might not be "truth" (what exists objectively) - and that doesn't matter most
- Example: Water is made of billions of tiny cells - knowing that gives awareness, control, ideas
- BUT that knowledge is **secondary** to the fact that we need water to live, secondary to the **experience of drinking water**

### The Purpose of (ur "reality")

**The point of your reality is to make your reality more beautiful. That's all.**

**Why enter your reality?**
- Because you want to **solve something**
- Because you want to **create something**
- Because we need a **chamber of reflection** to:
  - Figure out and align our many human drives in accordance with reality
  - Know what we want
  - So we can **act accordingly**

**It's not useless** - it's a practice of becoming a **student of you and your reality**. Most people don't do this because they think they're stuck in reality. But if your reality sucks, there's no point in living the same life without changing anything. You can use your realm of thought, upgrade it, and use it to set your intentions.

**Become a student of you and your reality.**

**We are trying to help people discover their best game - that's the point.**

You gotta figure out: **What is YOUR game that you are playing?**

### Building Your Inner Story

**What is the inner story?** It's what's going on in your head.

**The Deep Truth**:
- All you are is **someone**
- But **someone is ALL YOU ARE**
- Do you know someone? Do you know yourself?

**The Point**: You can write your inner story by reflecting about it. That's part of the point - **to figure out who you are**.

We're helping people **build their inner story** through:
- Capturing what you care about
- Reflecting in your chamber
- Discovering patterns, connections, meaning
- Understanding yourself through what you choose to capture and how you organize it

### Caring Proves You're Human

**Caring shows you have heart. That's what proves you're human. When you care.**

**That's why beauty and ugly matter** - because it's the foundation of who you are.

**From there**, you can decide how you want to steer your intention. Knowing the "why" - going deeper into your heart - is possible.

**Example of Reflection**:
- Initially you might just care about LUST LUST LUST
- With deeper reflection, you realize the reason why lust is a thing
- You see how it results in ugly
- You can course correct
- Like it might feel beauty at the moment - lust looks like it will create more beauty at the moment
- But then it actually doesn't
- So you ask yourself: **Is this what I want?**

**This reflection is what it means to study yourself and your reality.**

**THEN THE QUESTION IS: WHAT DO YOU WANT TO DO?**

### When The Game Begins: Setting Goals

**The game hasn't begun until you set a goal.**

**What happens when you set a goal**:
- Your **rocket ship** in your reality starts moving
- You **depart from reality** (the globe) and start collecting relevant somethings
- Your reality becomes **colored by this intention** and aligns to this goal
- The ship (representative of your **attention**) leaves the globe of reality
- It goes into your **realm of somethings**
- It brings to the forefront the **relevant question marks**
- **Revealing the question marks** - showing you what matters for this goal

**This is when our tool will shine**:
- Intentions guide everything
- You can have a **hierarchy of intentions**
- Dreams you are headed towards
- Your reality reorganizes around your goals
- Relevant somethings surface based on what you're trying to create/solve

### Not About Frameworks - About What YOU Want

**The Core Truth**: The answer to "what do I do about something?" is NOT a framework. The answer is: **do what you want**.

That's the core of it.

### A Tool of Tools

**What we're building**: A tool of tools to help you do what you want - like trying to make **Roblox Studio but for real life**.

**Current Reality**: This is fundamentally limited to what I want. That's all I know. But I want a lot.

**The Plan**:
- Start here, with what I want
- Get people to use it
- Help me build out and flesh out the tool
- The tool that helps you - no, **addicts you** - to doing what you want

### Here & Now

**"I am just a kid."**

This is what I want, here & now.

---

### Why Capture Something?

**Because it matters more than the moment had space for it.**

Because it matters more than you had the ability to express in the moment.

**You capture something because you cared about something.**

### Why Did You Care?

I don't know. There could be plenty of reasons:
- Perhaps something reminded you of a previous experience
- Maybe a previous experience caused you to dislike/like something without you even realizing why
- Maybe because you found **beauty** in something
- Maybe because you found **ugly** in something
- Maybe because you found a **desire**, a deep-seated dream in something
- Maybe you cared about something because you are **just human**

### The Beauty of Infinite Layers

**The meaning of something could be infinitely layered.**

There's not always a logical reason you care about something.

**The important part**: You DO care.

That's the point we're trying to get across. You can infinitely question WHY you care, but it all rests on the fact that **you do, in fact, care**.

**That's the philosophical backing**: Something. Something you care about.

And from there, you can do anything you want about anything.

### The Catch: Finite Life

**You can care limitlessly... as long as you have life.**

And you have **? amount of life**. Unknown, but **finite**.

So you only have **? amount of time to care** and more importantly **express your care**.

**Therefore**:
- It's important WHAT you care about
- It's important what you CHOOSE to care about in the next moment
- **Most important**: What you're going to do about something

---

## 2. The Chamber: Where the Game Begins

### The Central Question

**Now you have something in your reality. This is where the game begins.**

Why? Because sure, you cared about something. But **now what are you going to do about it?**

### The Philosophy of Action

**What's the point of caring if you don't express your care?**

- What's the point of trashing your chamber?
- Without organizing it, clearing off cobwebs, using the meaning you've collected to create something beautiful?
- **There's no point caring about everything if you're going to do nothing about it**

### The Reality of Constraints

**Because of DEATH, you simply can't care about everything.**

Even worse: **You can only care and express your care for a small amount of somethings.**

*(Hint hint: that's ur "reality")*

### What To Do About Something

**Sometimes** the answer is: nothing to do right now, figure it out in the future.

**But most times**, there's something you can do about it:
- Even if it's just putting that something in the bigger context of your everything, your reality
- Even if it's connecting that something to a prior something
- Even if it's understanding how it relates to your existing world

### The Reimagined Chamber

We are going to reimagine the UX from the previous chamber.

This philosophical discussion establishes **what actions a user will take in the chamber** and **how it will be useful**.

---

## 3. Starting Point: The Globe (Reality)

**We start from the globe now - and it makes sense to. That's reality.**

- Reality = Earth = Where humans are
- The globe is the playfield
- Everything starts here, in physical space

**Technical Implementation**:
- Mobile browsers can access geolocation (with user permission)
- Geolocation API: `navigator.geolocation.getCurrentPosition()`
- Requires HTTPS (except localhost)
- User must explicitly allow location access
- Accuracy: GPS ~5-50m, WiFi ~20-100m

**The Question**: Can we do this in a computer? **Yes.** We can track where in reality somethings are captured.

---

## 4. The Capture Philosophy

### The Core Moment
The user, in physical reality, has an experience - whatever it is - and decides to capture it because **it's important, it has meaning, it is SOMEthing**. Once captured, it enters the user's reality.

We can assume the user cares about that something - otherwise they wouldn't have captured it.

### Explorer Mode
Users can capture to their heart's content - days in a row, weeks in a row. This is **Explorer Mode**: where the user is exploring reality, discovering and capturing meaning in an **unbounded fashion**.

---

## 4. Capture System Design

### Two-Page Architecture

---

## Page 1: Live-Capture (`/capture`)

**Purpose**: Lightweight streams of consciousness - type, speak, send

**Design Philosophy**:
- **Dark mode** (black screen)
- Simple, distraction-free
- No redirects after capture
- Fast, ephemeral bursts
- Text clears after send (ready for next)

### Layout

**Text Editor**:
- Fills entire screen
- Simple text input (no formatting, no placeholder)
- Dark background, light text
- Large, readable font

**Send Button** (Bottom Right):
- **Rocket ship icon** üöÄ
- On click: Animates in straight line from bottom-right to top-right corner
- Rotation adjusts to flight angle
- Fast animation + **whoosh sound effect**
- After send: Clears text, ready for next capture

**Microphone Button** (Bottom Center):
- White microphone icon
- Press & hold: Record while holding
- Double-click: Toggle persistent recording mode (turns dark red with white square stop icon)
- **Audio transcription**: Transcribe to text, show on screen
- User sends as text-only (no audio file storage)

### Behavior

**Normal Flow**:
1. Type or speak ‚Üí text appears
2. Click rocket ship ‚Üí Submit to DB ‚Üí Clear page ‚Üí Ready for next

**Multi-line Paste Detection**:
- If pasted text has **1+ newlines** ‚Üí **Immediately sink-transition to Deep-Capture** with text pre-populated
- Single paragraph pastes (no newlines) ‚Üí Stay in Live-Capture

**Manual Transfer to Deep-Capture**:
- **Double-click & hold anywhere in text editor** ‚Üí Sink-transition to Deep-Capture with text transferred
- Use this when you want advanced editing tools

**What NOT to do**:
- Don't paste large multi-line chunks here (auto-transfers to Deep-Capture)
- Don't expect formatting/styling (use Deep-Capture for that)

---

## Page 2: Deep-Capture (`/deep-capture`)

**Purpose**: Major editing, file upload, splitting, future formatting tools

**Design Philosophy**:
- **Light mode** (white/cream background)
- Minimal, Apple Notes aesthetic
- Advanced editing capabilities
- Preview splits before submit

### Layout

**Text Input Box**:
- White/cream background
- Simple, clean text editor
- Copy/paste-able

**File Upload Interface**:
- Upload photos, videos, handwritten images (OCR'd to text), PDFs, links
- **Audio files** ‚Üí Transcribe to text (no audio file storage)

**Send Button** (Bottom Right):
- Same rocket ship icon üöÄ
- Same animation (flies to top-right with whoosh)
- After send ‚Üí **Return to Live-Capture** (cleared, ready)

### Auto-Split Behavior

**How it works**:
- Text with newlines ‚Üí **Auto-split preview** (each line = 1 something)
- Split cells **spawn downward** in same window (vertical scroll)
- Each split = **separate text box with border**
- Can merge/adjust splits before sending

**Visual**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Text line 1             ‚îÇ  ‚Üê Split 1
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Text line 2             ‚îÇ  ‚Üê Split 2
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Text line 3             ‚îÇ  ‚Üê Split 3
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚Üì Vertical scroll
```

**Split Editor**:
- Reuse functionality from Chamber (Story 2.2)
- Instead of modal ‚Üí inline editing (cells mutate downward)
- Merge splits by clicking between cells
- Delete splits individually

### File Upload

**Supported Types**:
- **Photos**: Show preview, upload to Supabase Storage ‚Üí `media_url`
- **Videos**: Show thumbnail, upload to Supabase Storage ‚Üí `media_url`
- **Handwritten images**: OCR to text ‚Üí `text_content` only (not stored as image)
- **Audio files**: Transcribe to text ‚Üí `text_content` only (not stored as audio)
- **Links** (Instagram, TikTok, YouTube): Extract URL, store as `text_content` + link preview metadata
- **PDFs/EPUBs**: Extract text (future)

**Upload Flow**:
1. User selects files
2. Each file shows as separate preview (stacked vertically)
3. Processing happens (OCR, transcription, etc.)
4. User reviews all somethings before sending
5. Click rocket ship ‚Üí Submit all ‚Üí Return to Live-Capture

### Future Editing Tools (Planned)
- Font editor
- Style editor (bold, italic, colors)
- Rich text formatting
- Tagging interface
- Quick connections to existing somethings

---

## 5. The /my-reality/somewhere Page - "Somewhere, A Realm of Somethings"

**Route**: `/my-reality/somewhere` (manual navigation only - user types in URL)

**Purpose**: Visual representation of all captured somethings as an infinite, zoomable mystery map with chamber entry point

**Access**: Available when user is logged in (no automatic redirect from capture pages)

---

### Vision: Infinite Space Visualization

**Conceptual Name**: "Somewhere, A Realm of Somethings"

**Core Philosophy**: Create an interactive, infinite realm of curiosity where question marks represent somethings, and zooming transforms their visual scale while maintaining their infinite, unstructured nature.

**The Problem with Current System (v3.3)**:
- Fixed distribution patterns (1-5) or random spread (6+)
- Question marks scale down as count increases
- No sense of infinite space
- Hard to navigate many somethings
- No organization capability for the future

**The Solution: Infinite Zoomable Space**

---

### Visual Design (v3.4 - 3D Space with Fixed View)

**3D Implementation**: Three.js
- Fixed camera view (can't rotate, but can pan/zoom)
- Similar to globe zoom with 3D buildings from Story 2.7
- 45-degree angle default view (top-down-ish perspective)

**Background**: Perlin noise texture
- Cloud-like appearance
- Surrounds the bounded space of somethings
- Represents "Unknown" - the space outside organized somethings

**Question Marks**:
- **SVG-based**: Use `white-question-mark-emoji-clipart-original.svg`
- **Proper circle**: Bottom ellipse should be actual circle (not square)
- **Colorable**: Can change fill color (no default red - use grey/white)
- **All same size** (regardless of count)
- **Equally spaced** via invisible rhombi lattice
- **Floating animation**: Bob up and down very subtly (acute movement)

**Lattice Organization** (Invisible Structure):
- **Rhombi lattice pattern** - provides equal spacing
- **Rhombi are invisible** - user sees organic placement
- **At borders**: Rhombi pattern gets cut off at edge (no wrapping/mirroring)
- **Bounded space**: Default 50 somethings max per user
- **Per-user setting**: Max somethings limit stored in user profile

**The Border**:
- Visible boundary separating organized somethings from "Unknown"
- Perlin noise fills space outside border
- Border shape adapts to number of somethings

---

### Zoom Behavior - Three View Levels

**View 1: Default View (45-degree angle)**
- **Zoom Level**: Close/Medium
- **Camera Angle**: 45-degree top-down-ish perspective
- **What's Visible**: Individual question marks on one plane
- **Interactions**: Can pan (click-drag), zoom in/out (scroll), click to focus
- **Similar To**: Globe view with 3D buildings (Story 2.7)

**View 2: Bird's Eye View (zoomed out)**
- **Zoom Level**: Far
- **Camera Angle**: Auto-shifts from 45¬∞ to bird's eye (top-down)
- **What's Visible**: Cluster of dots (can't see ? details)
- **Visual**: Group of dots + border + Perlin noise around
- **Purpose**: See all somethings as a collection

**View 3: Max Zoom Out (extreme)**
- **Zoom Level**: Extreme far
- **What's Visible**: Single dot representing entire abode
- **Visual**: One dot = all somethings, surrounded by Perlin noise
- **Purpose**: View totality of "Somewhere, A Realm of Somethings"

**Zoom Transitions**:
- Smooth camera transitions between views
- Auto-shift camera angle based on zoom level
- Preserve spatial relationships during zoom

---

### Interaction Behavior (v3.4 - Desmos-like UI)

**Device Support**:
- **Desktop/Laptop**: Full support (primary experience)
- **iPad**: Supported
- **Mobile (phone)**: BLOCKED - show message "View on bigger screen"

**Pan/Drag**:
- **Click and drag** to move through the space
- **Swipable** (smooth, responsive)
- Somethings flow past as you navigate
- Bounded space (user-adjustable bounds)

**Zoom**:
- **Scroll wheel** to zoom in/out (desktop)
- **Pinch gesture** for iPad
- Smooth zoom transition
- Desmos-like UI feel

**Hover (on question marks in Default View)**:
- Something content appears underneath the question mark
- Content has higher z-index (appears above other question marks)
- Content disappears when hover ends

**Click (on question mark)**:
- **Zoom to focus**: Camera zooms in on clicked question mark
- **Display content**: Show just that question mark and its content
- **Isolated view**: Only the clicked something is visible
- **Zoom out to return**: Scroll out or click outside to return to Default View

**Click-Drag to Pan** (in Default View):
- Click and hold background (not a question mark)
- Drag to move through the space
- Smooth, responsive panning (Desmos-like feel)

**Hover on Clicked ?**:
- N/A - clicking zooms to isolated view instead of locking content

---

### Equal Spacing Algorithm

**Key Principle**: Each question mark has equal radius around it, no overlap

**Implementation Approach**:
1. **Grid-less distribution**: No imposed grid, organic placement
2. **Force-directed layout**: Somethings repel each other to maintain spacing
3. **Infinite canvas**: Positions can extend infinitely in all directions
4. **Consistent spacing**: Minimum distance between any two question marks

**Example Spacing**:
- If 10 somethings: Spread with ~500px radius each
- If 100 somethings: Spread with ~500px radius each (just more spread out)
- If 1000 somethings: Spread with ~500px radius each (space extends further)

**No Size Scaling**: Unlike v3.3, question marks DON'T shrink as count increases. Space just extends.

---

### Content Display

**What Shows** (same as v3.3):
- **Text**: Full text content (all text, not truncated)
- **Photo**: Show the actual photo
- **Video**: Show video thumbnail
- **Link**: Link preview card

**Content Position**:
- Appears **underneath** the question mark
- Z-index **above** other question marks
- Positioned relative to zoom level (scales with zoom)

---

### Navigation Features & Chamber Entry

**Rocket Ship / Space Ship (Bottom Left)**:
- **Page Load Animation Sequence**:
  1. Page loads zoomed out showing Unknown (Perlin noise) - spaceship NOT visible
  2. Camera zooms to home screen showing spread of all question mark dots
  3. Spaceship appears in bottom left
  4. Text appears above spaceship: "ENTER CHAMBER" (all caps)

- **Chamber Entry Flow**:
  1. User clicks on spaceship
  2. Spaceship flies to nearest unorganized something (most recent)
  3. Spaceship slowly zooms out of vision, heading toward that something
  4. Whole screen slowly goes black
  5. Screen blinks back into vision
  6. **Chamber View appears**: Circle with content in middle, care bar underneath

**Search Bar (Bottom Center)**:
- Current: Placeholder (no filtering yet)
- Future: Search text ‚Üí zoom/pan to matching somethings

**Minimap (Future)**:
- Small overview of entire space
- Shows your current view position
- Click to jump to different areas

---

### Chamber View (Organization Interface)

**When to Show**: After spaceship animation sequence completes

**Visual Layout**:
- **Center**: Content circle displaying the current something
- **Top Right**: Change to "Something #X" (instead of count legend)
- **Bottom Center**: Care bar (existing - modifications planned for future)
- **Bottom Right**: "Send to Abode" with dropdown

**Send to Abode Dropdown**:
- **Options**:
  - Dreams
  - Beauty
  - Ugly
  - Rules of Reality
  - Create New (custom abode)

**Abode System** (Initial Implementation):
- Each abode is a **space randomly assigned** in my-reality
- Uses same **hexagonal lattice** structure as "Somewhere"
- **Dynamic expansion**: When more space needed (creating abode or sending something):
  - Expand the "Known" region
  - Shrink the "Unknown" (Perlin noise) by one layer
- Abodes start small, grow based on number of somethings they contain

**Chamber Purpose**:
- Process unorganized somethings
- Decide what to do with each one
- Organize into meaningful abodes (Dreams, Beauty, Ugly, Rules of Reality, custom)
- Gateway between raw capture and organized reality

---

### Empty State

**If user has 0 somethings**:
- Show message: "No somethings captured yet. Start capturing at /capture"
- Link to `/capture` page

---

### Future Enhancements

**Coloring System**:
- Question mark colors based on vibe (Beauty spectrum: grey ‚Üí colored)
- High vibe (beauty) = brighter colors
- Low vibe (ugly) = darker colors

**Connections**:
- Connections visible as lines between question marks
- Lines represent relationships, patterns

**Clustering**:
- Somethings with similar meaning cluster closer
- Visual patterns emerge over time

**Abodes/Regions**:
- Named regions of space (Lil Wayne abode, work, relationships)
- User can create boundaries and labels

**Intention-Based Navigation**:
- Set a goal/intention ‚Üí rocket ship flies toward relevant somethings
- Question marks light up based on relevance
- Space reorganizes around your intention

**Detail View**:
- Click to navigate to full something detail page
- Edit, add connections, set vibe rating

---

## 6. Technical Considerations

### Mobile App Experience
- Reference: https://ios.gadgethacks.com/how-to/turn-any-website-into-full-screen-app-your-iphone-0384426/
- Goal: Simulate native mobile app experience using website
- Implementation research needed

### User Experience Principles
1. **Zero Friction**: No confirmation messages, no redirects
2. **Continuous Flow**: Enable rapid consecutive captures
3. **Distraction-Free**: Minimal UI, maximum focus
4. **Confidence**: Silent but reliable submission
5. **Unbounded Exploration**: Support extended capture sessions

---

## 7. Future Features to Verify

- **Chat feature** with friends on website
- Chat should add meaning to and ping parts of your reality
- **Handwriting scanning** enhancement from images (journal pics ‚Üí parsed text)

---

## 8. Implementation Details (Answered)

### Transition Effects
1. **Sink-transition (Live ‚Üí File-Capture)**:
   - Slow ripple-away effect (not immediate)
   - Maintains illusion of solid capture page
   - Triggered by double-click and hold
   - Animation playfulness encouraged for exploration

### Audio Recording
2. **Recording Length**:
   - MVP: Use free tier limits (whatever is available)
   - Future: Infinite recording capability
   - Visual feedback: Button color change only (dark red when recording)

### File Upload
3. **Upload Behavior**:
   - Size limits: Support regular iPhone images, videos, voice memos
   - Progress indication: Files "zoom away" animation
     - Files appear held when first uploaded to file-capture page
     - When user confirms send: files zoom into corner (giving illusion of entering reality)
     - Live-capture page replaces file-capture after zoom completes
   - No loading bars or text confirmations

### Text Capture
4. **Auto-save**:
   - Yes, auto-save enabled
   - Text persists if user navigates away mid-type
   - Returns to exact state when user comes back

---

## 9. Summary: What We're Building

### **The Core Loop**

```
EXPLORE (Live-Capture / Deep-Capture)
   ‚Üì
   Capture somethings (text, photos, videos, audio ‚Üí all become text or media)
   ‚Üì
   Somethings enter your reality (raw, unprocessed)
   ‚Üì
/ur-reality (Mystery Map)
   ‚Üì
   See all somethings as question marks
   ‚Üì
CHAMBER (Future - not yet defined)
   ‚Üì
   Choose what to do about somethings
   ‚Üì
   Ask: Why care? What is it? What to do? What can I do?
   ‚Üì
REALITY MAP (Future - connections, dreams, goals)
   ‚Üì
   Navigate processed somethings, discover patterns
   ‚Üì
   Return when stuck to see what you already know
```

---

### **Phase 1: Capture + Mystery Map (Current Focus)**

**What to Build**:

1. **Live-Capture Page** (`/capture`)
   - Dark mode, simple text editor
   - Rocket ship send button (bottom right, animated)
   - Mic button (transcribe to text)
   - Multi-line paste ‚Üí auto-transition to Deep-Capture
   - Double-click & hold ‚Üí transfer to Deep-Capture

2. **Deep-Capture Page** (`/deep-capture`)
   - Light mode, minimal aesthetic
   - Text input + file upload
   - Auto-split on newlines (preview before send)
   - Audio ‚Üí transcribe to text
   - Handwriting OCR ‚Üí text
   - Return to Live-Capture after send

3. **/ur-reality Page**
   - Dark blue space background
   - Grey cartoon question marks (auto-scaling distribution)
   - Hover to preview, click to lock open
   - Show full content (text, photos, video thumbnails, link previews)

**Database**: Already ready (somethings table from Story 2.1)

---

### **Phase 2: The Chamber (Future)**

**Purpose**: Help you choose what to do about somethings

**The Core Function**:
- We need to make (ur "reality") **queryable with intention**
- You have all these somethings, but you need to decide **what your intention is** to actually access it
- When someone figures out their intention and the LLM that lives in your reality gets that command, then you are able to **connect more somethings**

**How it Works**:
- Use our experiences in reality to **enhance our realm of thought**
- The realm of thought's whole purpose: **direct ourselves through reality in a way that optimally creates our future**
- Understand your intentions and help curate them
- A thinking aid that helps you choose what you want to do

**Concepts to Explore**:
- Vibe spectrum (Beauty ‚Üê‚Üí Ugly)
- Meaning map (why you care, what it is)
- Action choice (dreams, goals, connections, abilities)
- Track what you CAN/CAN'T do
- Intention-based querying system (natural language to your reality's LLM)

**NOT yet defined** - will discover through using the capture + mystery map first

---

### **Phase 3: Reality Map (Future)**

**Purpose**: Navigate your processed reality

**Concepts to Explore**:
- Connections between somethings (web of meaning)
- Dreams to pursue, goals to organize
- Patterns over time (how your heart responds)
- Abilities tracker (strengthen weaknesses)
- Thematic abodes (Lil Wayne abode, relationships, work, etc.)

**NOT yet defined** - will discover through using the Chamber

---

*This document shapes the PRD and influences all current and future development goals.*

# Future Enhancements & Feature Ideas

## Deep-Capture Page

### Rocket Send Animation Enhancement
**Status**: Future Enhancement
**Priority**: Nice-to-have / Polish
**Date Added**: 2025-11-09

**Current State**:
- Rocket flies away when send is clicked
- Simple animation (flies to corner and disappears)

**Proposed Enhancement**:
Full animated sequence when rocket is clicked:
1. All somethings in the package animate/fly toward center
2. Somethings visually "pack" into a box/package
3. Package hops/jumps into the rocket
4. Rocket flies off with the package
5. Then navigate to Live-Capture

**Technical Notes**:
- Could use Framer Motion or CSS keyframe animations
- Sequence timing: ~2-3 seconds total
- Make skippable or add reduced-motion preference check
- Coordinate with navigation delay (currently 1 second)

**User Experience**:
- More delightful and playful interaction
- Visual confirmation of what's being sent
- Matches the metaphor of "packaging" and "sending"

---

## Link Preview

### Real Link Metadata Fetching
**Status**: Current Placeholder Implementation
**Priority**: Medium
**Date Added**: 2025-11-09

**Current State**:
- `fetchLinkMetadata()` returns basic URL info
- No actual OpenGraph/metadata scraping

**Proposed Enhancement**:
- Implement server-side metadata fetching (avoid CORS)
- Support OpenGraph, Twitter Cards, oEmbed
- Show real thumbnails for:
  - YouTube videos
  - Instagram posts
  - TikTok videos
  - Twitter/X posts
  - General websites

**Technical Notes**:
- Create API route `/api/link-preview`
- Use libraries like `open-graph-scraper` or similar
- Cache results to avoid repeated fetches
- Handle rate limits for social media platforms

---

## OCR / Text Extraction

### Better OCR with OpenAI Vision API
**Status**: Removed (was using Tesseract.js)
**Priority**: Medium
**Date Added**: 2025-11-09

**Current State**:
- OCR completely removed (was poor quality)
- All images treated as photos

**Proposed Enhancement**:
- Use OpenAI Vision API for text extraction
- Better accuracy for handwritten text
- Better handling of complex layouts
- Multi-language support

**Technical Notes**:
- API route to handle image ‚Üí GPT-4 Vision ‚Üí extracted text
- Cost consideration: ~$0.01 per image
- User can still edit extracted text before sending
- Keep option to skip OCR and just upload as photo

---

## Audio Transcription

### WhisperLive or OpenAI Whisper Integration
**Status**: Placeholder (currently no transcription)
**Priority**: Low
**Date Added**: 2025-11-09

**Current State**:
- Audio files upload without transcription
- Shows "Audio transcription not yet supported"

**Proposed Enhancement**:
- Integrate OpenAI Whisper API for transcription
- Or use WhisperLive for real-time transcription
- Generate text_content from audio automatically

**Technical Notes**:
- API route for audio ‚Üí Whisper ‚Üí text
- Show loading state during transcription
- Allow user to edit/review transcript
- Keep original audio file + transcript

---

## Performance Optimizations

### Image Compression Before Upload
**Status**: Future Enhancement
**Priority**: Low
**Date Added**: From QA review

**Description**:
- Compress images client-side before upload
- Reduce file sizes for faster uploads
- Use browser Canvas API or library like `browser-image-compression`

### Lazy Load Tesseract.js (if re-enabled)
**Status**: N/A (OCR removed)
**Priority**: N/A

**Description**:
- If OCR is re-enabled, lazy load the Tesseract library
- Reduces initial bundle size (~2MB)

---

## UI/UX Improvements

### Next.js Image Component
**Status**: Linting Warning
**Priority**: Low
**Date Added**: From QA review

**Description**:
- Replace `<img>` tags with Next.js `<Image />` component
- Better performance (automatic optimization, lazy loading)
- Reduced bandwidth usage

**Files to Update**:
- `app/deep-capture/DeepCaptureClient.tsx`
- `app/components/LinkPreviewCard.tsx`
- `app/components/SomethingContent.tsx`
- Others (see lint warnings)

---

## Ideas Log

### Batch Operations UI
- Allow selecting multiple items in package
- Bulk delete
- Reorder items before sending

### Undo/Redo
- Undo delete actions
- Redo split/merge operations

### Keyboard Shortcuts
- Enter to add to package
- Cmd/Ctrl+Enter to send
- Cmd/Ctrl+Z for undo

### Save Draft
- Save current package state to localStorage
- Resume later if user navigates away
- "You have unsent items" reminder

---

*This document tracks future enhancement ideas for the Deep-Capture page and related features.*
